{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: pyro-ppl in c:\\programdata\\anaconda3\\envs\\mbml\\lib\\site-packages (1.3.1)\nRequirement already satisfied: numpy>=1.7 in c:\\programdata\\anaconda3\\envs\\mbml\\lib\\site-packages (from pyro-ppl) (1.18.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\envs\\mbml\\lib\\site-packages (from pyro-ppl) (3.2.1)\nRequirement already satisfied: torch>=1.4.0 in c:\\programdata\\anaconda3\\envs\\mbml\\lib\\site-packages (from pyro-ppl) (1.5.0)\nRequirement already satisfied: pyro-api>=0.1.1 in c:\\programdata\\anaconda3\\envs\\mbml\\lib\\site-packages (from pyro-ppl) (0.1.2)\nRequirement already satisfied: tqdm>=4.36 in c:\\programdata\\anaconda3\\envs\\mbml\\lib\\site-packages (from pyro-ppl) (4.46.0)\nRequirement already satisfied: future in c:\\programdata\\anaconda3\\envs\\mbml\\lib\\site-packages (from torch>=1.4.0->pyro-ppl) (0.18.2)\n"
    }
   ],
   "source": [
    "!pip install pyro-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import constraints\n",
    "import functools\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, JitTraceEnum_ELBO, TraceEnum_ELBO\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal, AutoGuideList, AutoDelta\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the modifed data matrix, where the documents are of equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(32211, 1500)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "import requests, io\n",
    "r = requests.get('https://github.com/MikkelGroenning/MBML_project/blob/master/data/processed/upsampled_data.npy?raw=true')\n",
    "\n",
    "data = np.load(io.BytesIO(r.content)).astype('int32')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of 32.211 speeches, each with a length of 1500 words. We therefore only look at a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = data[:100]\n",
    "data_sub = np.vectorize({k:v for (k,v) in zip(np.unique(data_sub), np.arange(len(np.unique(data_sub))))}.get)(data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = data_sub.max() + 1\n",
    "num_topics = 25\n",
    "num_docs = data_sub.shape[0]\n",
    "num_words_per_doc = data_sub.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these things defined we can now make an LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data=None, batch_size=None):\n",
    "    \"\"\" Make a plate of size num_topics with name \"topics\" and define a variable \"topic_words\".\n",
    "          This represents the phi above. Use the equivalent of a uniform distribution for it  \"\"\"\n",
    "    with pyro.plate(\"topics\", num_topics):\n",
    "        topic_words = pyro.sample(\"topic_words\", dist.Dirichlet(torch.ones(num_words) / num_words))\n",
    "\n",
    "    \"\"\" Make two (nested) plates in here. One over documents and one over words\n",
    "          Documents, called \"documents\":\n",
    "          The plate over the documents should hold a variable \"doc_topics\" representing the theta above.\n",
    "            Use the equivalent of a uniform distribution for it.\n",
    "          \n",
    "          Words, called \"words\":\n",
    "          The plate over words, should have a topic assignment for each word (z_{i,j} above) which \n",
    "            should be enumerated.\n",
    "          The second variable should be the words themselves which should be drawn from the \"topic_words\"\n",
    "            using the assigned z_{i,j} and the observed data.\n",
    "\n",
    "     \"\"\"\n",
    "    with pyro.plate(\"documents\", num_docs) as ind:\n",
    "        if data is not None:\n",
    "            with pyro.util.ignore_jit_warnings():\n",
    "                assert data.shape == (num_words_per_doc, num_docs)\n",
    "            data = data[:, ind]\n",
    "        doc_topics = pyro.sample(\"doc_topics\", dist.Dirichlet(torch.ones(num_topics)/ num_topics))\n",
    "        with pyro.plate(\"words\", num_words_per_doc):\n",
    "            # The word_topics variable is marginalized out during inference,\n",
    "            # achieved by specifying infer={\"enumerate\": \"parallel\"} and using\n",
    "            # TraceEnum_ELBO for inference. Thus we can ignore this variable in\n",
    "            # the guide.\n",
    "            word_topics = pyro.sample(\"word_topics\", dist.Categorical(doc_topics), infer={\"enumerate\": \"parallel\"})\n",
    "            data = pyro.sample(\"doc_words\", dist.Categorical(topic_words[word_topics]), obs=data)\n",
    "\n",
    "    return topic_words, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_torch = torch.tensor(data_sub.T).long()\n",
    "W_torch.shape\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we do LAD like we did in the exercises, first we make a gudie and then run the LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 9806400000 bytes. Buy new RAM!\n(no backtrace available)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b75615653520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# do gradient steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0melbo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_torch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m25\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#print('.', end='')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mbml\\lib\\site-packages\\pyro\\infer\\svi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# get loss and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mbml\\lib\\site-packages\\pyro\\infer\\traceenum_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrainable_params\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melbo_particle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[0mloss_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0melbo_particle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mloss_particle\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0melbo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mbml\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mbml\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 9806400000 bytes. Buy new RAM!\n(no backtrace available)"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "def my_local_guide(data=None, batch_size=None):\n",
    "    topic_words_posterior = pyro.param(\n",
    "            \"topic_words_posterior\",\n",
    "            lambda: torch.ones(num_topics, num_words),\n",
    "            constraint=constraints.positive)\n",
    "    with pyro.plate(\"topics\", num_topics):\n",
    "        pyro.sample(\"topic_words\", dist.Dirichlet(topic_words_posterior))\n",
    "    \n",
    "    doc_topics_posterior = pyro.param(\n",
    "            \"doc_topics_posterior\",\n",
    "            lambda: torch.ones(num_docs, num_topics),\n",
    "            constraint=constraints.simplex)\n",
    "    with pyro.plate(\"documents\", num_docs, batch_size) as ind:\n",
    "        pyro.sample(\"doc_topics\", dist.Delta(doc_topics_posterior[ind], event_dim=1))\n",
    "    \n",
    "guide = AutoGuideList(model)\n",
    "guide.add(AutoDiagonalNormal(pyro.poutine.block(model, expose=['doc_topics'])))\n",
    "guide.add(my_local_guide)  # automatically wrapped in an AutoCallable\n",
    "\n",
    "guide = my_local_guide\n",
    "\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=3)\n",
    "\n",
    "optim = ClippedAdam({'llommer': 0.05})\n",
    "svi = SVI(model, guide, optim, elbo)\n",
    "\n",
    "# Define the number of optimization steps\n",
    "n_steps = 750\n",
    "\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(W_torch, batch_size=16)\n",
    "    if step % 25 == 0:\n",
    "        #print('.', end='')\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amortized LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use amortized inference of the local variables. This is acheived by using a multi-layer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5])\n"
    }
   ],
   "source": [
    "layer_sizes = np.arange(98,103)\n",
    "layer_sizes = torch.tensor(layer_sizes)\n",
    "print(layer_sizes.size())\n",
    "\n",
    "def make_predictor(num_words, layer_sizes):\n",
    "    layer_sizes = ([num_words] +\n",
    "                   [int(s) for s in torch.split(layer_sizes,1)] +\n",
    "                   [num_topics])\n",
    "    logging.info('Creating MLP with sizes {}'.format(layer_sizes))\n",
    "    layers = []\n",
    "    for in_size, out_size in zip(layer_sizes, layer_sizes[1:]):\n",
    "        layer = nn.Linear(in_size, out_size)\n",
    "        layer.weight.data.normal_(0, 0.001)\n",
    "        layer.bias.data.normal_(0, 0.001)\n",
    "        layers.append(layer)\n",
    "        layers.append(nn.Sigmoid())\n",
    "    layers.append(nn.Softmax(dim=-1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "def parametrized_guide(predictor, data, batch_size=None):\n",
    "    # Use a conjugate guide for global variables.\n",
    "    topic_weights_posterior = pyro.param(\n",
    "            \"topic_weights_posterior\",\n",
    "            lambda: torch.ones(num_topics),\n",
    "            constraint=constraints.positive)\n",
    "    topic_words_posterior = pyro.param(\n",
    "            \"topic_words_posterior\",\n",
    "            lambda: torch.ones(num_topics, num_words),\n",
    "            constraint=constraints.greater_than(0.5))\n",
    "    with pyro.plate(\"topics\", num_topics):\n",
    "        pyro.sample(\"topic_weights\", dist.Gamma(topic_weights_posterior, 1.))\n",
    "        pyro.sample(\"topic_words\", dist.Dirichlet(topic_words_posterior))\n",
    "\n",
    "    # Use an amortized guide for local variables.\n",
    "    pyro.module(\"predictor\", predictor)\n",
    "    with pyro.plate(\"documents\", num_docs, batch_size) as ind:\n",
    "        data = data[:, ind]\n",
    "        # The neural network will operate on histograms rather than word\n",
    "        # index vectors, so we'll convert the raw data to a histogram.\n",
    "        counts = (torch.zeros(num_words, ind.size(0)).scatter_add(0, data, torch.ones(data.shape)))\n",
    "        doc_topics = predictor(counts.transpose(0, 1))\n",
    "        pyro.sample(\"doc_topics\", dist.Delta(doc_topics, event_dim=1))\n",
    "\n",
    "learning_rate = 0.05\n",
    "\n",
    "predictor = make_predictor(num_words, layer_sizes)\n",
    "guide = functools.partial(parametrized_guide, predictor)\n",
    "# Elbo = JitTraceEnum_ELBO if args.jit else TraceEnum_ELBO\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=3)\n",
    "optim = ClippedAdam({'lr': learning_rate})\n",
    "svi = SVI(model, guide, optim, loss=elbo)\n",
    "\n",
    "# Define the number of optimization steps\n",
    "n_steps = 5\n",
    "\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(W_torch, batch_size=2)\n",
    "    if step % 1 == 0:\n",
    "        #print('.', end='')\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import  vocabulary, X, X_tfidf, corpus, corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {v:k for v, k in sorted((value, key) for (key,value) in vocabulary.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 20\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus[:500],\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average topic coherence: -2.0881.\n[([(0.008943842, 'fru'),\n   (0.00655985, 'venstr'),\n   (0.006472275, 'statsminist'),\n   (0.0060022757, 'kr'),\n   (0.005951143, 'kris'),\n   (0.00567152, 'peng'),\n   (0.0056012115, 'sf'),\n   (0.0055634277, 'mennesk'),\n   (0.0055069444, 'politik'),\n   (0.005256012, 'radikal'),\n   (0.0051922924, 'land'),\n   (0.0051377746, 'økonomisk'),\n   (0.0050867614, 'hr'),\n   (0.005072784, 'folkeparti'),\n   (0.0049760165, 'økonomi'),\n   (0.004265044, 'ung'),\n   (0.004113977, 'ansvar'),\n   (0.003916533, 'samfund'),\n   (0.0039004118, 'nye'),\n   (0.0037868014, 'konservativ')],\n  -1.0390022561287233),\n ([(0.025277242, 'kommun'),\n   (0.013765038, 'lovforslag'),\n   (0.008171043, 'borg'),\n   (0.007006078, 'københavn'),\n   (0.00602456, 'hr'),\n   (0.005409857, 'land'),\n   (0.004537714, 'folkeparti'),\n   (0.0043712156, 'enkelt'),\n   (0.0043359795, 'stud'),\n   (0.004196492, 'netop'),\n   (0.004156884, 'forskel'),\n   (0.0039674025, 'eu'),\n   (0.0039598, 'regl'),\n   (0.0038858296, 'opgav'),\n   (0.0036484986, 'ændring'),\n   (0.00353603, 'konsekvens'),\n   (0.0035199083, 'gæld'),\n   (0.0034818354, 'problem'),\n   (0.0034706478, 'beslutningsforslag'),\n   (0.0034689605, 'handl')],\n  -1.1823419473699806),\n ([(0.025647784, 'kommun'),\n   (0.005642169, 'folk'),\n   (0.0053718523, 'privat'),\n   (0.005109893, 'problem'),\n   (0.00499384, 'socialdemokrat'),\n   (0.004899376, 'statsminist'),\n   (0.0046765967, 'peng'),\n   (0.0045311525, 'udvalg'),\n   (0.0043649822, 'kr'),\n   (0.0043553663, 'hr'),\n   (0.0042242343, 'simpelt'),\n   (0.004173441, 'hør'),\n   (0.0040792148, 'offent'),\n   (0.0039487947, 'enkelt'),\n   (0.003923722, 'boligområd'),\n   (0.0038116716, 'fået'),\n   (0.003516083, 'netop'),\n   (0.0035143162, 'energiforbrug'),\n   (0.0034429163, 'tænk'),\n   (0.003409886, 'folkeparti')],\n  -1.450818510675382),\n ([(0.016212424, 'uddan'),\n   (0.0076889386, 'problem'),\n   (0.007328952, 'løsning'),\n   (0.0065681064, 'lovforslag'),\n   (0.00649176, 'erhvervsuddan'),\n   (0.0064567584, 'land'),\n   (0.006152893, 'folkeparti'),\n   (0.005645454, 'su'),\n   (0.005306933, 'forsørg'),\n   (0.0053045596, 'centr'),\n   (0.005217471, 'ung'),\n   (0.0047656936, 'venstr'),\n   (0.0047409665, 'sag'),\n   (0.004728921, 'mennesk'),\n   (0.0047114072, 'arbejdsmarked'),\n   (0.0046194308, 'afgør'),\n   (0.004500887, 'part'),\n   (0.004089783, 'beslutningsforslag'),\n   (0.0040335604, 'aftal'),\n   (0.003943622, 'voks')],\n  -1.5940594761783138),\n ([(0.016387938, 'nordisk'),\n   (0.015082642, 'opholdstillad'),\n   (0.010802958, 'humanitær'),\n   (0.009424893, 'samarbejd'),\n   (0.008252408, 'hr'),\n   (0.007954645, 'sag'),\n   (0.0077024573, 'fru'),\n   (0.00732375, 'praksis'),\n   (0.0071973107, 'irak'),\n   (0.006705959, 'land'),\n   (0.006409044, 'venstr'),\n   (0.006282773, 'folketing'),\n   (0.0055685854, 'afvist'),\n   (0.0052577956, 'nord'),\n   (0.005247256, 'sf'),\n   (0.0052166646, 'vedtag'),\n   (0.0047390964, 'folkeparti'),\n   (0.0047067683, 'parti'),\n   (0.0043275924, 'ændr'),\n   (0.004249265, 'kristens')],\n  -1.6157254921173998),\n ([(0.011966428, 'lovforslag'),\n   (0.0097345365, 'strandbeskyttelseslinj'),\n   (0.009516226, 'venstr'),\n   (0.007043957, 'byg'),\n   (0.006881014, 'gmo'),\n   (0.0067716665, 'stør'),\n   (0.006207929, 'natur'),\n   (0.005632044, 'miljø'),\n   (0.0055534346, 'fru'),\n   (0.0050995625, 'lov'),\n   (0.004600871, 'auk'),\n   (0.004571302, 'stil'),\n   (0.0045067547, 'hr'),\n   (0.004233053, 'ida'),\n   (0.00409714, 'sag'),\n   (0.004087412, 'sf'),\n   (0.004054298, 'konservativ'),\n   (0.00395457, 'klart'),\n   (0.003906808, 'konsekvens'),\n   (0.0038825597, 'tillad')],\n  -1.7963131052310173),\n ([(0.014512768, 'hr'),\n   (0.009498822, 'lovforslag'),\n   (0.008237457, 'led'),\n   (0.0059907413, 'sag'),\n   (0.0057750656, 'uddan'),\n   (0.0055177473, 'regl'),\n   (0.0050150217, 'lov'),\n   (0.0047823177, 'frank'),\n   (0.0047797295, 'aaen'),\n   (0.0047013015, 'forsvar'),\n   (0.0046535092, 'gæld'),\n   (0.0042959233, 'undersøg'),\n   (0.0042348485, 'problem'),\n   (0.004169927, 'udsend'),\n   (0.004157644, 'soldat'),\n   (0.0040818914, 'forskel'),\n   (0.0040635136, 'netop'),\n   (0.004005768, 'ræk'),\n   (0.0036716743, 'bjarn'),\n   (0.0036293403, 'job')],\n  -1.874078110311261),\n ([(0.01851931, 'fag'),\n   (0.0091017075, 'reform'),\n   (0.00851126, 'gymnasiereform'),\n   (0.007109676, 'elev'),\n   (0.006382881, 'lær'),\n   (0.0063696415, 'styrk'),\n   (0.0057876753, 'alm'),\n   (0.005057453, 'venstr'),\n   (0.0047874073, 'studieforbered'),\n   (0.004513154, 'folkeparti'),\n   (0.004382058, 'justering'),\n   (0.004287212, 'undervisning'),\n   (0.0041891932, 'gymnasi'),\n   (0.0035858748, 'vælg'),\n   (0.0035464074, 'ræk'),\n   (0.0035016255, 'naturvidenskab'),\n   (0.003445155, 'sprog'),\n   (0.0033373632, 'liberal'),\n   (0.003263056, 'fokus'),\n   (0.0032465209, 'glad')],\n  -1.9232754371517091),\n ([(0.009162266, 'fru'),\n   (0.0074090525, 'hr'),\n   (0.007282328, 'sf'),\n   (0.0070592435, 'lovforslag'),\n   (0.005706543, 'folkeparti'),\n   (0.0051529366, 'egent'),\n   (0.0050428915, 'kr'),\n   (0.004647083, 'eu'),\n   (0.0045847152, 'socialdemokrati'),\n   (0.0042842203, 'kommun'),\n   (0.004067713, 'politi'),\n   (0.004033772, 'sag'),\n   (0.0039292756, 'land'),\n   (0.0037134376, 'peng'),\n   (0.0037106, 'schmidt'),\n   (0.0035414938, 'situation'),\n   (0.0034910855, 'forbud'),\n   (0.0032372447, 'hvert'),\n   (0.0032131975, 'villy'),\n   (0.0031229865, 'søvndal')],\n  -1.9598944515596466),\n ([(0.032048587, 'ordning'),\n   (0.024198435, 'forsøg'),\n   (0.015029312, 'aftal'),\n   (0.0118277045, 'peng'),\n   (0.0100899255, 'økonomisk'),\n   (0.009366842, 'land'),\n   (0.009299745, 'kulturskol'),\n   (0.009208228, 'børn'),\n   (0.008250296, 'fortsæt'),\n   (0.0081231855, 'frivil'),\n   (0.007854, 'vid'),\n   (0.007012176, 'ung'),\n   (0.006559136, 'sigt'),\n   (0.0065407394, 'positiv'),\n   (0.006356172, 'god'),\n   (0.006317229, 'erfaring'),\n   (0.0060645165, 'parti'),\n   (0.0059314417, 'irakisk'),\n   (0.0057606595, '2010'),\n   (0.0055154837, 'kør')],\n  -1.9959870216939761),\n ([(0.030596638, 'landbrug'),\n   (0.029732656, 'hr'),\n   (0.015645543, 'vækst'),\n   (0.0153991245, 'grøn'),\n   (0.010864306, 'miljø'),\n   (0.009116151, 'natur'),\n   (0.008953578, 'bjarn'),\n   (0.008808085, 'lausts'),\n   (0.0069636116, '000'),\n   (0.006579115, 'lovforslag'),\n   (0.0061399876, 'midl'),\n   (0.006085915, 'økologi'),\n   (0.00579242, 'reduc'),\n   (0.005463424, 'mål'),\n   (0.0049097487, 'erhverv'),\n   (0.0045490717, 'landmænd'),\n   (0.004525401, 'folkeparti'),\n   (0.004466539, 'økologisk'),\n   (0.0043991935, 'socialdemokrati'),\n   (0.0043028602, 'per')],\n  -2.0010438766661416),\n ([(0.014098734, 'politi'),\n   (0.008864333, 'hr'),\n   (0.0074056657, 'folk'),\n   (0.0072243973, 'straf'),\n   (0.0069172727, 'lov'),\n   (0.0063451407, 'folkeparti'),\n   (0.006284696, 'lovforslag'),\n   (0.005770653, 'mennesk'),\n   (0.005473661, 'demonstration'),\n   (0.00534474, 'ophold'),\n   (0.0053223413, 'folketing'),\n   (0.0052636922, 'uro'),\n   (0.004699902, 'københavn'),\n   (0.0046461304, 'klimatopmød'),\n   (0.0046119564, 'læg'),\n   (0.0044800467, 'humanitært'),\n   (0.004458942, 'hør'),\n   (0.004246705, 'fred'),\n   (0.004227404, 'venstr'),\n   (0.0041024885, 'handl')],\n  -2.083505467995346),\n ([(0.017041516, 'kommun'),\n   (0.012918795, 'konkurrenceudsæt'),\n   (0.009970544, 'opgav'),\n   (0.009397916, 'leverandør'),\n   (0.00878032, 'kommunal'),\n   (0.008158484, 'privat'),\n   (0.004763991, 'mål'),\n   (0.0046717334, 'undersøg'),\n   (0.0040745004, 'israel'),\n   (0.0039792364, 'forskel'),\n   (0.00390456, 'offent'),\n   (0.0037075174, 'hjemmehjælp'),\n   (0.00346976, 'pct'),\n   (0.0034502505, 'udvalg'),\n   (0.0034093186, 'prehn'),\n   (0.0034025868, 'region'),\n   (0.0033887122, 'udgift'),\n   (0.0033708063, 'klart'),\n   (0.0031775401, 'beslutningsforslag'),\n   (0.0031064232, 'lev')],\n  -2.188657357846507),\n ([(0.009234642, 'daginstitution'),\n   (0.008913368, 'undersøg'),\n   (0.0072447355, 'frokostmåltid'),\n   (0.0069920276, 'børn'),\n   (0.006201687, 'sund'),\n   (0.0060592205, 'kommun'),\n   (0.0056492365, 'israel'),\n   (0.005580106, 'ræk'),\n   (0.0053075287, 'arbejdsgrup'),\n   (0.00525999, '2010'),\n   (0.0050036004, 'ørum'),\n   (0.005003007, 'jørgens'),\n   (0.0049899872, 'indfør'),\n   (0.004822037, 'januar'),\n   (0.0046329293, 'ordning'),\n   (0.0045093605, 'lovforslag'),\n   (0.0045060143, 'kl'),\n   (0.0043050214, 'rapport'),\n   (0.004042245, 'skyld'),\n   (0.003495505, 'part')],\n  -2.345853085553026),\n ([(0.014449001, 'aftal'),\n   (0.011367866, 'land'),\n   (0.0103998985, 'lovforslag'),\n   (0.008687633, 'hr'),\n   (0.0066674366, 'skat'),\n   (0.0057502664, 'selskab'),\n   (0.0049181413, 'fru'),\n   (0.004438328, 'regl'),\n   (0.0043638228, 'gæld'),\n   (0.0043296567, 'folketing'),\n   (0.0040841782, 'vestag'),\n   (0.0038945246, 'margreth'),\n   (0.0037415507, 'søvndal'),\n   (0.003613099, 'beskatning'),\n   (0.0035001002, 'indgå'),\n   (0.0034576694, 'villy'),\n   (0.0033980927, 'schweiz'),\n   (0.0032869044, 'sf'),\n   (0.0031859386, 'øvr'),\n   (0.003112182, 'schmidt')],\n  -2.391037099306623),\n ([(0.010637868, 'lovforslag'),\n   (0.0076785143, 'motorvej'),\n   (0.00675546, 'land'),\n   (0.005452669, 'eu'),\n   (0.0050656567, 'co2'),\n   (0.0049650115, 'lov'),\n   (0.004896956, 'omfat'),\n   (0.0047375583, 'trafik'),\n   (0.004559002, 'vedvar'),\n   (0.0045386604, 'energi'),\n   (0.0044111023, 'forbind'),\n   (0.004372595, 'projek'),\n   (0.0042736544, 'luftfart'),\n   (0.0038416807, 'vej'),\n   (0.003709224, 'politi'),\n   (0.0035984307, 'per'),\n   (0.0035398994, 'frederikssund'),\n   (0.003476823, 'kontrol'),\n   (0.003213078, 'vedtag'),\n   (0.003184545, 'bemærkning')],\n  -2.5536210875625533),\n ([(0.019106852, 'finansiel'),\n   (0.010480017, 'fusion'),\n   (0.009873139, 'bank'),\n   (0.008953416, 'aftal'),\n   (0.008739915, 'kris'),\n   (0.008279727, 'finanstilsyn'),\n   (0.007632206, 'lovforslag'),\n   (0.007617469, 'gebyr'),\n   (0.0072589777, 'virksom'),\n   (0.007129004, 'sektor'),\n   (0.0064857993, 'undersøg'),\n   (0.005407984, 'designskol'),\n   (0.0050995336, 'uddannelsesinstitution'),\n   (0.0050725173, 'tilsyn'),\n   (0.0046287104, 'uddan'),\n   (0.004573061, 'international'),\n   (0.004259671, 'indberetning'),\n   (0.004228116, 'ræk'),\n   (0.004017299, 'enhedslist'),\n   (0.003982637, 'sag')],\n  -2.5976563949286358),\n ([(0.019035045, 'land'),\n   (0.015837442, 'produk'),\n   (0.013643673, 'eu'),\n   (0.0104616275, 'forbrug'),\n   (0.0097024245, 'tjenesteyd'),\n   (0.008024999, 'var'),\n   (0.0071801813, 'lovforslag'),\n   (0.0064103627, 'lov'),\n   (0.005394141, 'skattely'),\n   (0.00537415, 'sikker'),\n   (0.005353875, 'uland'),\n   (0.005321646, 'problem'),\n   (0.0051465817, 'aftal'),\n   (0.0049644653, 'skattelyland'),\n   (0.0045416174, 'selskab'),\n   (0.004364204, 'virksom'),\n   (0.0043210704, 'hvert'),\n   (0.004289246, 'stil'),\n   (0.004113537, 'produktsikkerhedslov'),\n   (0.00409042, 'konvention')],\n  -2.9479952561102047),\n ([(0.018487904, 'region'),\n   (0.015541876, 'opgav'),\n   (0.013671057, 'spil'),\n   (0.0070657395, 'udvalg'),\n   (0.0060628117, 'pok'),\n   (0.0060610687, 'mad'),\n   (0.005949858, 'lovforslag'),\n   (0.0057553933, 'lov'),\n   (0.0051831678, 'peng'),\n   (0.004699951, 'forældr'),\n   (0.0046049664, 'privat'),\n   (0.0045750435, 'institution'),\n   (0.0044978606, 'undersøg'),\n   (0.004474682, 'regionsråd'),\n   (0.00415534, 'måltid'),\n   (0.0041140313, 'ram'),\n   (0.0040028477, 'kommunalreform'),\n   (0.0038230794, 'debat'),\n   (0.0037424539, 'varetag'),\n   (0.0036136704, 'madordning')],\n  -2.967217768523605),\n ([(0.0067213234, 'børneattest'),\n   (0.005409765, 'lovforslag'),\n   (0.004577423, 'forening'),\n   (0.0040797684, 'forsvarskommando'),\n   (0.00398124, 'folkeparti'),\n   (0.0037962229, 'mennesk'),\n   (0.0037428653, 'demonstration'),\n   (0.003688364, 'børn'),\n   (0.003683543, 'spar'),\n   (0.0032183933, 'fag'),\n   (0.0028610278, 'snak'),\n   (0.0028127227, 'afvikling'),\n   (0.002810863, 'konto'),\n   (0.0026033868, 'boligsikring'),\n   (0.0025550306, 'foretag'),\n   (0.0025343194, 'medarbejd'),\n   (0.002513234, 'opmærksom'),\n   (0.0024780403, 'valg'),\n   (0.0024387697, 'tjen'),\n   (0.002428837, 'omfat')],\n  -3.254740473252765)]\n"
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmbmlcondafd08ce0341164d10a999be67eed30d97",
   "display_name": "Python 3.7.7 64-bit ('mbml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}